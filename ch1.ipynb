{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93309c48-e4d3-4903-b03c-05d64fefe07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the Azure OpenAI model using LangChain\n",
    "model = AzureChatOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),   # e.g., \"https://<your-resource-name>.openai.azure.com/\"\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),           # Azure OpenAI API Key\n",
    "    api_version=\"2023-07-01-preview\",                    # API version (check your Azure OpenAI resource for the correct one)\n",
    "    model=os.getenv(\"AZURE_OPENAI_MODEL_NAME\"),          # This should be your Azure deployment name (not model like \"gpt-3.5-turbo\")\n",
    "    temperature=0                                         # Temperature for deterministic output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6374b29-25ec-44a5-8a35-8225a157c41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blue and vast, often filled with fluffy white clouds during the day, and dotted with stars at night.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "model.invoke(\"The sky is\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c80b92fd-c377-4e01-81ae-cbb834faee93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "# Create a prompt as a list of messages\n",
    "prompt = [HumanMessage(content=\"What is the capital of France?\")]\n",
    "\n",
    "# Invoke the model\n",
    "model.invoke(prompt).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2955d57-bd30-4d4c-8522-f52b88dfe661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris!!!'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Define messages\n",
    "system_msg = SystemMessage(\n",
    "    content=\"You are a helpful assistant that responds to questions with three exclamation marks.\"\n",
    ")\n",
    "human_msg = HumanMessage(\n",
    "    content=\"What is the capital of France?\"\n",
    ")\n",
    "\n",
    "# Invoke the model with a message list\n",
    "model.invoke([system_msg, human_msg]).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e423983-b3ec-4def-97a1-97493020398c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='Answer the question based on the\\n    context below. If the question cannot be answered using the information \\n    provided, answer with \"I don\\'t know\".\\n\\nContext: The most recent advancements in NLP are being driven by Large \\n        Language Models (LLMs). These models outperform their smaller \\n        counterparts and have become invaluable for developers who are creating \\n        applications with NLP capabilities. Developers can tap into these \\n        models through Hugging Face\\'s `transformers` library, or by utilizing \\n        OpenAI and Cohere\\'s offerings through the `openai` and `cohere` \\n        libraries, respectively.\\n\\nQuestion: Which model providers offer LLMs?\\n\\nAnswer: ')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate.from_template(\"\"\"Answer the question based on the\n",
    "    context below. If the question cannot be answered using the information \n",
    "    provided, answer with \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: \"\"\")\n",
    "\n",
    "template.invoke({\n",
    "    \"context\": \"\"\"The most recent advancements in NLP are being driven by Large \n",
    "        Language Models (LLMs). These models outperform their smaller \n",
    "        counterparts and have become invaluable for developers who are creating \n",
    "        applications with NLP capabilities. Developers can tap into these \n",
    "        models through Hugging Face's `transformers` library, or by utilizing \n",
    "        OpenAI and Cohere's offerings through the `openai` and `cohere` \n",
    "        libraries, respectively.\"\"\",\n",
    "    \"question\": \"Which model providers offer LLMs?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "161bbcab-f141-443d-a63d-f40ae3ffc732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I translated the sentence \"I love programming\" into French, which is \"J\\'adore programmer.\"'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a helpful assistant. Answer all questions to the best \n",
    "        of your ability.\"\"\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "chain.invoke({\n",
    "    \"messages\": [\n",
    "        (\"human\",\"\"\"Translate this sentence from English to French: I love \n",
    "            programming.\"\"\"),\n",
    "        (\"ai\", \"J'adore programmer.\"),\n",
    "        (\"human\", \"What did you just say?\"),\n",
    "    ],\n",
    "}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ee1abd-2cf1-43ba-a098-3238a1893aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
